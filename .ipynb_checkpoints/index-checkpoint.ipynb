{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aeab74b-73e5-4819-a3b0-77657626411d",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7598865b-7049-47fc-b0ed-f6b18acef0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import hashlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from flask import Flask, render_template, request, jsonify, send_from_directory\n",
    "from keras.models import load_model\n",
    "from keras.models import save_model\n",
    "import io\n",
    "from tensorflow.keras.models import load_model\n",
    "from werkzeug.utils import secure_filename\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3894bdf5-04a5-4016-8aeb-49ca594ea440",
   "metadata": {},
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0cfa0399-13e3-4627-b85c-47a4ef2ab32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_path = 'dataset/train/REAL'\n",
    "fake_images_path = 'dataset/train/FAKE'\n",
    "real_test_path = 'dataset/test/REAL'\n",
    "fake_test_path = 'dataset/test/FAKE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b39691-a050-46ad-94d5-8fa34c50b57d",
   "metadata": {},
   "source": [
    "## Load Images from Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ef99b68-a18d-431e-8386-9c234df7d684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, label):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            img = img.resize((128, 128))\n",
    "            img = np.array(img)\n",
    "            images.append([img, label])\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {filename}: {e}\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d89eb36-10b0-4369-8572-f6683b2434aa",
   "metadata": {},
   "source": [
    "### Convert to DataFrame\n",
    "\n",
    "####  1. Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f461c6-ae11-438b-ab51-0c9759906438",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = load_images_from_folder(real_images_path, label=0)  # Label 0 for real\n",
    "fake_images = load_images_from_folder(fake_images_path, label=1)  # Label 1 for fake\n",
    "\n",
    "# Combine fake and real\n",
    "all_images = real_images + fake_images\n",
    "\n",
    "# Convert to df\n",
    "df = pd.DataFrame(all_images, columns=['image', 'label'])\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b1ebb4-cd56-4283-afd6-55b825b6a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89389b6c-2bb0-446e-9871-134d3bbefd6a",
   "metadata": {},
   "source": [
    "#### 2. Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab105d03-e6cd-4874-86ca-e522ec0b8c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test_images = load_images_from_folder(real_test_path, label=0)  # Label 0 for real\n",
    "fake_test_images = load_images_from_folder(fake_test_path, label=1)  # Label 1 for fake\n",
    "\n",
    "# Combine fake and real\n",
    "all_test_images = real_test_images + fake_test_images\n",
    "\n",
    "# Convert to df\n",
    "df_test = pd.DataFrame(all_test_images, columns=['image', 'label'])\n",
    "\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b895e1d8-54be-488a-8f7d-27da2c5a55bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe8ae6c-1165-4c80-8ba5-de643fc2ba67",
   "metadata": {},
   "source": [
    "### Define and Use Image Display Functions\n",
    "\n",
    "Below we view what is contained in the df we created that is the images, since the images have been stretched they appear to be of low quality\n",
    "\n",
    "#### 1. Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7203942-5726-43dc-beb6-2e97ef074681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image_array):\n",
    "    plt.imshow(image_array)\n",
    "    plt.axis('off')  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c92d99a-5d01-42a5-a48b-678ed2cfb305",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(df.iloc[0]['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a55dc2-b988-4357-8498-3df571158127",
   "metadata": {},
   "source": [
    "#### 2. Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efaf9e0-45b6-4247-9850-625a6223c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First image in the test df\n",
    "display_image(df_test.iloc[0]['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38af000f-5a0f-494d-98de-41b1e3309055",
   "metadata": {},
   "source": [
    "### Data Cleaning: Handling Duplicates, Missing Data, and Corrupted Images\n",
    "\n",
    "#### 1. Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25947a6-89c1-43d1-9d8e-c7fb5b9582bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_image_data(df):\n",
    "    # Hashing\n",
    "    print(\"Removing duplicate images...\")\n",
    "    df['img_hash'] = df['image'].apply(lambda img: hashlib.md5(img.tobytes()).hexdigest())\n",
    "    df.drop_duplicates(subset='img_hash', inplace=True)\n",
    "    # Drop the hash column after removing duplicates\n",
    "    df.drop(columns=['img_hash'], inplace=True)  \n",
    "\n",
    "    # Check for missing labels\n",
    "    print(\"Checking for missing labels...\")\n",
    "    missing_labels = df['label'].isnull().sum()\n",
    "    if missing_labels > 0:\n",
    "        print(f\"Found {missing_labels} missing labels. Dropping rows with missing labels...\")\n",
    "        df.dropna(subset=['label'], inplace=True)\n",
    "\n",
    "    # Verify images are loaded correctly and not corrupted\n",
    "    print(\"Verifying image integrity...\")\n",
    "    valid_images = []\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            img = Image.fromarray(row['image'])\n",
    "            img.verify()  # Is image corrupted\n",
    "            valid_images.append(True)\n",
    "        except Exception as e:\n",
    "            print(f\"Corrupted image detected at index {i}: {e}\")\n",
    "            valid_images.append(False)\n",
    "    \n",
    "    df = df[valid_images]\n",
    "\n",
    "    # Reset index after cleaning\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb73e50-5c23-4c08-adb7-1ecc00fb903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function to train df\n",
    "df_cleaned = clean_image_data(df)\n",
    "\n",
    "# Display the cleaned train df\n",
    "print(\"Cleaned DataFrame:\")\n",
    "print(df_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee1ffe6-aba2-4304-8fd5-22f5c8716004",
   "metadata": {},
   "source": [
    "#### 2. Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aeaf00-fb19-44b1-b9e1-64489e3330ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function to test df\n",
    "df_test_cleaned = clean_image_data(df_test)\n",
    "\n",
    "# Display the cleaned test df\n",
    "print(\"Cleaned DataFrame:\")\n",
    "print(df_test_cleaned.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c658de52-6f9f-49b1-a87a-e39135df698d",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903b87e4-1942-470b-a843-6dc02aada6ee",
   "metadata": {},
   "source": [
    "#### 1. Resize and Display Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274e572c-2f42-4da1-9dd7-06790186b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sizes of all images\n",
    "def get_image_sizes(image_list):\n",
    "    sizes = [img.shape[:2] for img, _ in image_list]\n",
    "    return sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176b16b2-85d5-4841-908c-1b9d29083250",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = get_image_sizes(all_images)\n",
    "sizes_df = pd.DataFrame(sizes, columns=['Height', 'Width'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5337cf5e-9ac1-49fb-9348-4b3c8b88f54e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of image sizes\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sizes_df['Height'].hist(bins=30, color='purple', alpha=0.7)\n",
    "plt.title('Distribution of Image Heights')\n",
    "plt.xlabel('Height')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sizes_df['Width'].hist(bins=30, color='pink', alpha=0.7)\n",
    "plt.title('Distribution of Image Widths')\n",
    "plt.xlabel('Width')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c9d39e-e2f7-4b73-9e4d-d43c923bc474",
   "metadata": {},
   "source": [
    "According the output above the image size is consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d863788-e91d-4061-9db2-e193ca0757fc",
   "metadata": {},
   "source": [
    "#### 2. Check Class Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ee111a-aff9-4275-8084-79317631df04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each label\n",
    "label_counts = df['label'].value_counts()\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "label_counts.plot(kind='bar', color=['purple', 'pink'], alpha=0.7)\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(ticks=[0, 1], labels=['REAL', 'FAKE'], rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f021dfa5",
   "metadata": {},
   "source": [
    "The above show that there is no class imbalance, all the labels have equal number of images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f5301",
   "metadata": {},
   "source": [
    "#### 3. Sample Image Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05027c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(images, labels, num_images=5, dpi=300):\n",
    "    plt.figure(figsize=(15, 10), dpi=dpi)  \n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(images[i])  \n",
    "        plt.title(f\"Label: {labels[i]}\")\n",
    "        plt.axis('off')  \n",
    "    plt.show()\n",
    "\n",
    "images_to_display = [df.iloc[i]['image'] for i in range(5)]\n",
    "labels_to_display = [df.iloc[i]['label'] for i in range(5)]\n",
    "\n",
    "display_images(images_to_display, labels_to_display, num_images=5, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6287c06-f3db-49b2-ab42-3adc8191bf29",
   "metadata": {},
   "source": [
    "#### 4. Image Aspect Ratio Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad766c0-d7de-4d84-aa91-7f25be1d8831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate aspect ratios\n",
    "aspect_ratios = [img.shape[1] / img.shape[0] for img, _ in all_images]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(aspect_ratios, bins=30, color='purple', alpha=0.7)\n",
    "plt.title('Aspect Ratio Distribution')\n",
    "plt.xlabel('Aspect Ratio')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c76e722",
   "metadata": {},
   "source": [
    "According to the above output the Image Aspet Ratio distribution is consistent throughout the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b7cdfe-24ba-4494-9300-745654e65430",
   "metadata": {},
   "source": [
    "#### 5. Analyze Pixel Intensity Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c456e5-b254-4eb5-bbb1-804ff962ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_intensity_distribution(image_list):\n",
    "    pixel_values = []\n",
    "    for img, _ in image_list:\n",
    "        pixel_values.append(img.mean(axis=(0, 1)))  \n",
    "    pixel_values = np.array(pixel_values).flatten()  \n",
    "    return pixel_values\n",
    "\n",
    "pixel_values = get_pixel_intensity_distribution(all_images)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(pixel_values, bins=50, color='purple', alpha=0.7)\n",
    "plt.title('Average Pixel Intensity Distribution')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75de9c10",
   "metadata": {},
   "source": [
    "The above indicates a balanced range of brightness levels in both real and fake images. This suggests the model will need to focus on complex features like texture and noise, rather than just brightness, to distinguish between real and fake images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553280e1-8021-42dd-a053-1f12e391f909",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89d3a8-d1b5-41c6-9f4b-9089687defab",
   "metadata": {},
   "source": [
    "#### 1. Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dbe9da-acf0-4744-b255-f40ba76032e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce image size to 64x64 to save memory\n",
    "image_size = (64, 64)\n",
    "\n",
    "# Convert the images and labels to NumPy arrays and resize images\n",
    "X_train = np.array([cv2.resize(img, image_size) for img in df['image']], dtype=np.float32)\n",
    "y_train = np.array([label for label in df['label']], dtype=np.float32)\n",
    "\n",
    "# Normalize the pixel values to the range 0-1\n",
    "X_train = X_train / 255.0\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3016618b-5659-4b9a-8230-e24586ac85a7",
   "metadata": {},
   "source": [
    "#### 2. Define CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e46d1ca-2597-4fd6-9b6a-612bfa2860fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')  # 2 classes for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba28b59-0051-4af5-ae01-1fa8e78c9f84",
   "metadata": {},
   "source": [
    "#### 3. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858770c9-0fe3-4745-8586-2e4161bd1cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,  \n",
    "    epochs=10,\n",
    "    validation_data=(X_val, y_val)  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb9e9ef-991b-4d4b-80d3-ef8840f750ff",
   "metadata": {},
   "source": [
    "#### 4. Evaluate the Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3415a1f8-9019-46ff-97f1-a81aa4225d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator \n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadd19e1-103b-491d-8b37-30f2b06308b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test data generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'dataset/test',  # Directory where test images are located\n",
    "    target_size=(64, 64),  # Ensure this matches the input size of your model\n",
    "    batch_size=32,  # Batch size\n",
    "    class_mode='categorical',  # Class mode should match how you trained the model\n",
    "    shuffle=False  # Important to set to False for evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cf1a4f-10f7-421e-9cd9-ea6a4394b54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model \n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf35a66-6909-4b3d-8bcd-901ecd739383",
   "metadata": {},
   "source": [
    "#### 5. Generate Predictions and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca958e77-7f18-4027-be9c-7b9639292978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the test data generator\n",
    "y_pred = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size + 1)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "y_true = test_generator.classes\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d9d297-bb84-4cfb-8b0d-59678dc62a93",
   "metadata": {},
   "source": [
    "#### 6. Plot the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94bc6e6-900b-457f-a3d1-fac4274e85cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_generator.class_indices.keys())\n",
    "disp.plot(cmap=plt.cm.Purples)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dff28a-c5fe-466c-aa57-8b2bacb2a774",
   "metadata": {},
   "source": [
    "#### 7. Print classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40b1608-de36-43bd-956d-18aa99c644ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys())\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae1380-7578-4116-a6a7-e7c9e32cb5b0",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c49243a-fcb4-4b6a-8d69-050c63cd0653",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/cnn_model.h5')  \n",
    "model.save('model/cnn_deepfake_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251a658a",
   "metadata": {},
   "source": [
    "### Load Trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4928f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model/cnn_deepfake_model.keras')\n",
    "\n",
    "# Load test data \n",
    "# Reduce image size to 64x64 to match train data\n",
    "image_size = (64, 64)\n",
    "X_test = np.array([cv2.resize(img, image_size) for img in df_test['image']], dtype=np.float32)\n",
    "\n",
    "# Normalize test data\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Make predictions\n",
    "y_test_predictions = model.predict(X_test)\n",
    "predicted_labels = np.argmax(y_test_predictions, axis=1)  # Get class labels\n",
    "\n",
    "# Map predictions to readable labels\n",
    "label_mapping = {0: 'REAL', 1: 'FAKE'}\n",
    "df_test['PREDICTION'] = predicted_labels\n",
    "df_test['PREDICTION_LABEL'] = df_test['PREDICTION'].map(label_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6b0b0f",
   "metadata": {},
   "source": [
    "### Save the DataFrame with predictions to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0c9e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('data_pred/deepfake_predictions.csv', index=False)\n",
    "\n",
    "pred = pd.read_csv('data_pred/deepfake_predictions.csv')\n",
    "print(pred.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0474940e",
   "metadata": {},
   "source": [
    "### Front-End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1da2b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Flask app\n",
    "app = Flask(__name__, template_folder='public/templates', static_folder='static')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72c0f2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 14 variables whereas the saved optimizer has 26 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = load_model('model/cnn_deepfake_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a5ff485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    image_size = (64, 64)\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, image_size)\n",
    "    img = np.array(img, dtype=np.float32) / 255.0\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8734a38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc2fb797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the directory to save the uploaded files\n",
    "UPLOAD_FOLDER = 'uploads'\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "app.config['ALLOWED_EXTENSIONS'] = {'png', 'jpg', 'jpeg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d16872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file part'}), 400\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "    if file and allowed_file(file.filename):\n",
    "        filename = secure_filename(file.filename)\n",
    "        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "        file.save(file_path)\n",
    "        prediction = make_prediction(file_path)\n",
    "        return jsonify({'prediction': prediction})\n",
    "    else:\n",
    "        return jsonify({'error': 'Invalid file format'}), 400\n",
    "\n",
    "def make_prediction(file_path):\n",
    "    img = preprocess_image(file_path)\n",
    "    prediction = model.predict(img)\n",
    "    \n",
    "    # Assuming the output is a probability for the \"Fake\" class\n",
    "    if prediction[0][1] > 0.5:\n",
    "        return \"Fake\"\n",
    "    else:\n",
    "        return \"Real\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7102885",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/uploads/<filename>')\n",
    "def uploaded_file(filename):\n",
    "    return send_from_directory(app.config['UPLOAD_FOLDER'], filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9123becc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [17/Aug/2024 21:08:49] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [17/Aug/2024 21:08:49] \"GET /static/banner.jpg HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [17/Aug/2024 21:08:50] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [17/Aug/2024 21:09:03] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [17/Aug/2024 21:09:23] \"POST /predict HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [17/Aug/2024 21:09:38] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [17/Aug/2024 21:09:39] \"\u001b[36mGET /static/banner.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [17/Aug/2024 21:09:39] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [17/Aug/2024 21:09:50] \"POST /predict HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [17/Aug/2024 21:09:58] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [17/Aug/2024 21:09:58] \"\u001b[36mGET /static/banner.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [17/Aug/2024 21:09:58] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [17/Aug/2024 21:17:45] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [17/Aug/2024 21:17:45] \"\u001b[36mGET /static/banner.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [17/Aug/2024 21:17:46] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [17/Aug/2024 21:17:58] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [17/Aug/2024 21:18:03] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [17/Aug/2024 21:18:15] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "def run_app():\n",
    "    if not os.path.exists(app.config['UPLOAD_FOLDER']):\n",
    "        os.makedirs(app.config['UPLOAD_FOLDER'])\n",
    "    app.run(debug=True, use_reloader=False)\n",
    "\n",
    "# Run Flask app in a separate thread\n",
    "thread = Thread(target=run_app)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce035f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
